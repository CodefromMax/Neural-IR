{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSV_to_JSON.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodefromMax/Neural-IR/blob/main/CSV_to_JSON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "new665FA0UpZ"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "file = 'ZhaoqiR.csv'\n",
        "json_file = 'Data1.json'\n",
        "\n",
        "#Read CSV File\n",
        "def read_CSV(file, json_file):\n",
        "    csv_rows = []\n",
        "    with open(file) as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        field = reader.fieldnames\n",
        "        for row in reader:\n",
        "            csv_rows.extend([{field[i]:row[field[i]] for i in range(len(field))}])\n",
        "            ######\n",
        "            #plan on converting the csv\n",
        "\n",
        "            #Create three dictionaries, query type, options, explantion\n",
        "            #Store the answer\n",
        "            # if 'general vs specific' == 0, specific = 1 otherwise specific = 0.\n",
        "            #Slicing the option to get the recipe 211dqdacf, the description, and the explanation \n",
        "            #Add the dictionaries as the fields in the json\n",
        "\n",
        "    convert_write_json(csv_rows, json_file)\n",
        "\n",
        "#Convert csv data into json\n",
        "def convert_write_json(data, json_file):\n",
        "     with open(json_file, \"w\") as f:\n",
        "        f.write(json.dumps(data, sort_keys=False, indent=4, separators=(',', ': '))) #for pretty\n",
        "        f.write(json.dumps(data))\n",
        "\n",
        "read_CSV(file,json_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "path = \"data.json\"\n",
        "df = pd.read_csv(path)\n",
        "df = df.dropna()\n",
        "# list of dictionaries \n",
        "data = []\n",
        "\n",
        "for row in range(len(df)):  \n",
        "  item = {}  \n",
        "  query_type = {}\n",
        "  correct_answer = {}\n",
        "  options = {}\n",
        "  explanations = {}\n",
        "\n",
        "  # formatting and extracting properties from csv\n",
        "  query = df.loc[row, \"Query\"]\n",
        "  match_query_type(row, query_type)\n",
        "  match_options_explanations(row, options, correct_answer, explanations)\n",
        "\n",
        "  # mapping properties into item dictionary\n",
        "  item[\"query\"] = query\n",
        "  item[\"query_type\"] = query_type\n",
        "  item[\"options\"] = options\n",
        "  item[\"correct_answer\"] = correct_answer\n",
        "  item[\"explanations\"] = explanations\n",
        "\n",
        "  data.append(item)\n",
        "\n",
        "# converting dictionary to json using function from above\n",
        "with open(\"data.json\", \"w\") as f:\n",
        "        f.write(json.dumps(data, sort_keys=False, indent=4, separators=(',', ': '))) #for pretty\n",
        "        f.write(json.dumps(data))\n",
        "\n",
        "\n",
        "def match_query_type(row, query_type):\n",
        "  # General (0) vs. specific (1)\n",
        "  temp = df.loc[row,\"General (0) vs. specific (1)\"]\n",
        "  query_type[\"General\"] = 1 - temp\n",
        "  query_type[\"Specific\"] = temp\n",
        "\n",
        "  # Objective (0) vs. subjective (1)\n",
        "  temp = df.loc[row,\"Objective (0) vs. subjective (1)\"]\n",
        "  query_type[\"Objective\"] = 1 - temp\n",
        "  query_type[\"Subjective\"] = temp\n",
        "\n",
        "  # Indirect (0) vs. direct (1)\n",
        "  temp = df.loc[row,\"Indirect (0) vs. direct (1)\"]\n",
        "  query_type[\"Indirect\"] = 1 - temp\n",
        "  query_type[\"Direct\"] = temp\n",
        "\n",
        "  # Simple (0) vs. compound (1) logic (AND/OR)\n",
        "  temp = df.loc[row,\"Simple (0) vs. compound (1) logic (AND/OR)\"]\n",
        "  query_type[\"Simple\"] = 1 - temp\n",
        "  query_type[\"Compound\"] = temp\n",
        "\n",
        "  # Negation (1)\n",
        "  query_type[\"Negated\"] = df.loc[row,\"Negation (1)\"]\n",
        "\n",
        "  # Analogical (1)\n",
        "  query_type[\"Analogical\"] = df.loc[row,\"Analogical (1)\"]\n",
        "\n",
        "  # Temporal (1)\n",
        "  query_type[\"Temporal\"] = df.loc[row,\"Temporal (1)\"]\n",
        "\n",
        "\n",
        "def match_options_explanations(row, options, correct_answer, explanations):\n",
        "\n",
        "  temp = df.loc[row, \"Correct Answer\"]\n",
        "  id_description = temp.split(\": \")\n",
        "  # correct recipe id mapped to description\n",
        "  correct_answer[id_description[0]] = df.loc[row,\"correct_description\"]\n",
        "  # correct recipe id as an option mapped to description\n",
        "  options[id_description[0]] = df.loc[row,\"correct_description\"]\n",
        "  # correct recipe id mapped to explanation\n",
        "  explanations[id_description[0]] = df.loc[row,\"Correct_explanation\"]\n",
        "\n",
        "  for i in range (1, 5):\n",
        "    option_string = \"Option \" + i\n",
        "    description_string = \"description_\" + i\n",
        "    explanation_string = \"explanation_\" + i\n",
        "\n",
        "    temp = df.loc[row, option_string]\n",
        "    id_description = temp.split(\": \")\n",
        "    # option recipe id mapped to description\n",
        "    options[id_description[0]] = df.loc[row, description_string]\n",
        "    # option recipe id mapped to explanation\n",
        "    explanations[id_description[0]] = df.loc[row, explanation_string]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsuWLWJncdlw",
        "outputId": "bbf998f2-c089-433d-f34b-ba1630a6b532"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "def match_query_type(row, query_type):\n",
        "  print(1)\n",
        "  # General (0) vs. specific (1)\n",
        "  temp = df.loc[row,\"General (0) vs. specific (1)\"]\n",
        "  query_type[\"General\"] = 1 - temp\n",
        "  query_type[\"Specific\"] = temp\n",
        "\n",
        "  # Objective (0) vs. subjective (1)\n",
        "  temp = df.loc[row,\"Objective (0) vs. subjective (1)\"]\n",
        "  query_type[\"Objective\"] = 1 - temp\n",
        "  query_type[\"Subjective\"] = temp\n",
        "\n",
        "  # Indirect (0) vs. direct (1)\n",
        "  temp = df.loc[row,\"Indirect (0) vs. direct (1)\"]\n",
        "  query_type[\"Indirect\"] = 1 - temp\n",
        "  query_type[\"Direct\"] = temp\n",
        "\n",
        "  # Simple (0) vs. compound (1) logic (AND/OR)\n",
        "  temp = df.loc[row,\"Simple (0) vs. compound (1) logic (AND/OR)\"]\n",
        "  query_type[\"Simple\"] = 1 - temp\n",
        "  query_type[\"Compound\"] = temp\n",
        "\n",
        "  # Negation (1)\n",
        "  query_type[\"Negated\"] = df.loc[row,\"Negation (1)\"]\n",
        "\n",
        "  # Analogical (1)\n",
        "  query_type[\"Analogical\"] = df.loc[row,\"Analogical (1)\"]\n",
        "\n",
        "  # Temporal (1)\n",
        "  query_type[\"Temporal\"] = df.loc[row,\"Temporal (1)\"]\n",
        "  return query_type\n",
        "\n",
        "def match_options_explanations(row, options, correct_answer, explanations):\n",
        "  print(1)\n",
        "  temp = df.loc[row, \"Correct Answer\"]\n",
        "  id_description = temp.split(\": \")\n",
        "  # correct recipe id mapped to description\n",
        "  correct_answer[id_description[0]] = df.loc[row,\"correct_description\"]\n",
        "  # correct recipe id as an option mapped to description\n",
        "  options[id_description[0]] = df.loc[row,\"correct_description\"]\n",
        "  # correct recipe id mapped to explanation\n",
        "  explanations[id_description[0]] = df.loc[row,\"Correct_explanation\"]\n",
        "\n",
        "  for i in range (1, 5):\n",
        "    option_string = \"Option \" + i\n",
        "    description_string = \"description_\" + i\n",
        "    explanation_string = \"explanation_\" + i\n",
        "\n",
        "    temp = df.loc[row, option_string]\n",
        "    id_description = temp.split(\": \")\n",
        "    # option recipe id mapped to description\n",
        "    options[id_description[0]] = df.loc[row, description_string]\n",
        "    # option recipe id mapped to explanation\n",
        "    explanations[id_description[0]] = df.loc[row, explanation_string]\n",
        "\n",
        "    return options, correct_answer, explanations\n",
        "\n",
        "path = \"ZhaoqiR.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "df = df.dropna()\n",
        "# list of dictionaries \n",
        "data = []\n",
        "\n",
        "for row in range(99):  \n",
        "  print(1)\n",
        "  item = {}  \n",
        "  query_type = {}\n",
        "  correct_answer = {}\n",
        "  options = {}\n",
        "  explanations = {}\n",
        "\n",
        "  # formatting and extracting properties from csv\n",
        "  query = df.loc[row, \"Query\"]\n",
        "  query_type = match_query_type(row, query_type)\n",
        "  \n",
        "  options, correct_answer, explanations = match_options_explanations(row, options, correct_answer, explanations)\n",
        "\n",
        "  # mapping properties into item dictionary\n",
        "  item[\"query\"] = query\n",
        "  item[\"query_type\"] = query_type\n",
        "  item[\"options\"] = options\n",
        "  item[\"correct_answer\"] = correct_answer\n",
        "  item[\"explanations\"] = explanations\n",
        "\n",
        "  data.append(item)\n",
        "  print(1)\n",
        "\n",
        "# converting dictionary to json using function from above\n",
        "with open(\"data.json\", \"w\") as f:\n",
        "  f.write(json.dumps(data, sort_keys=False, indent=4, separators=(',', ': '))) #for pretty\n",
        "  f.write(json.dumps(data))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "EsvGDHU3zIWa",
        "outputId": "cf8bdc43-7ed3-49a2-cef0-6cdb1492b3f6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-6f4a4e83c1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;31m# formatting and extracting properties from csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m   \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m   \u001b[0mquery_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_query_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    836\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3774\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3776\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3778\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}